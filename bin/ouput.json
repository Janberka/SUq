UGLY

{
  "items": [
    {
      "properties": {
        "mainContentOfPage": [
          "\n\nSUq\n\nScraping Utility for lazy people.\nMIT Licensed\n\nHere's a simple node module that will allow you to asynchronously scrape opengraph tags, microformats, microdata, header tags, images, classic meta, and whatever else you want with minimal effort.\nYou can output the scraped data in the command line, or you can output scraped data as a JSON object.\nIf you don't want the scraped data yet, and still want to fine tune and grab more data from the html, no problem.  You can extend suq as much as you want, it doesn't care.\n\n\nRecipes\nCommand line Usage\nBasic Usage\nOpengraph\nMicroformat\nMicrodata\nHeaders\nImages\nMeta\nOptions\nSignature\nExtending\nMentions\n\n\nCommand line usage:\n\nScrape a website and output the data to command line.\n\nsuq can be used in the command line when installed globally, outputting scraped data to stdout\n\nnpm install suq -g\n\nsuq http://www.example.com > example.json\n\nsuq -u http://www.example.com -o example.json\n\nsuq --url http://www.example.com --output example.json\n\n\n\nBasic usage\n\nHow to scrape a website and convert structured data to json, and keep the html data as well (in case you're not done with it yet)\n\nvar suq = require('suq');\n\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        console.log('scraped json is:', JSON.stringify(json, null, 2));\n        console.log('html body is', body);\n    }\n\n});\n\n\nOpengraph\n\nHow to scrape a website and store its opengraph tags.\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var openGraphTags = json.og;\n        console.log(JSON.stringify(openGraphTags, null, 2));\n    }\n\n});\n\n\nMicroformat\n\nHow to scrape a website and store its microformats version 1 and 2 data.\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var microformat = json.microformat;\n        console.log(JSON.stringify(microformat, null, 2));\n    }\n\n});\n\n\nMicrodata\n\nHow to scrape a website and store its schema.org microdata.\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var microdata = json.microdata;\n        DoSomethingCool(microdata);\n    }\n\n});\n\n\nHeaders\n\nHow to scrape header tags from a URL:\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var headers = json.headers;\n\n        var title = json.headers.h1[0];\n        var subtitle = json.headers.h2[0];\n\n    }\n\n});\n\n\nImages\n\nHow to scrape image tag URLS from a website:\n\nvar suq = require('suq');\nvar _ = require('lodash');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var images = json.images;\n\n        _.each(images, function (src) {\n            makeSomeHTML('<img src=\"' + src + '\"/>');\n        });\n\n    }\n\n});\n\n\nMeta\n\nHow to scrape meta title and description from a URL:\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var title = json.meta.title;\n        var description = json.meta.description;\n    }\n\n});\n\nOptions\n\nYou can customize what SUq pulls from websites by using options (everything is turned on by default)\n\nHere is how you can scrape nothing but open graph tags:\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\nvar options = {\n    meta: false,\n    microdata: false,\n    microformats: false,\n    headers: false,\n    images: false,\n    og: true // or leave this blank since it is true by default\n}\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var openGraphTags = json.og;\n        console.log(JSON.stringify(openGraphTags, null, 2));\n    }\n\n}, options);\n\nOutput\n\nTBD\n\nOptions Table\n\n\n\nmetascrape meta tags\nmicrodatascrape microdata\nmicroformatsscrape microformats\nheadersscrape headers\nimagesscrape images\nogscrape open graph\n\n\n\n\nRemember, Everything is enabled by default.\n\n\nSignature\n\nIf you are familiar with signature patterns, you may find this helpful.  If not, you may ignore this :)\n\nsuq(String url, Callback( JSON err, JSON json, String body ) callback, Object options);\n\nExtending\n\nSUq is a node module that lets you scrape website data and customize what you want because it doesnt drop the html body from the request.\n\nIn this example we scrape an unordered list with the class \"grocerylist\" and scrape all the p tags too for fun.\n\nvar suq = require('suq');\nvar cheerio = require('cheerio');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    var $ = cheerio.load(body);\n\n\n    $('body').find('p').each(function(i, el) {\n\n        json.pTags.push($(el).text().trim());\n\n    });\n\n    $('body').find('ul.grocerylist').find('li').each(function(i, el) {\n\n        json.groceryList.push($(el).text().trim());\n\n    });\n\n    NowDoSomethingCool(json);\n});\n\nMentions\n\nSUq was made possible by:\n\n\ncheerio by Matt Mueller\nlodash by John-David Dalton\nmicrodata-node by Jan Potoms\nmicroformat-node by Glenn Jones\nminimist by James Halliday\nrequest by Mikeal Rogers\nopenGraphScraper by Josh Shemas\nAnd of course the awesome folks over at nodeJS.org\n\n\nA huge THANK YOU goes out to all of you for making this easy for me..  :)\n\nTODOS:\n\n\nAdd more explanations regarding options\n\n"
        ],
        "keywords": [
          "JavaScript"
        ]
      },
      "type": [
        "http://schema.org/WebPage"
      ]
    },
    {
      "properties": {
        "title": [
          "MattMcFarland"
        ],
        "url": [
          "/MattMcFarland"
        ]
      },
      "type": [
        "http://data-vocabulary.org/Breadcrumb"
      ]
    },
    {
      "properties": {},
      "type": [
        "http://data-vocabulary.org/Breadcrumb"
      ]
    },
    {
      "properties": {
        "title": [
          "SUq"
        ]
      }
    }
  ]
}


CLEAN


[
  {
    "type": "http://schema.org/WebPage",
    "props": {
      "mainContentOfPage": "\n\nSUq\n\nScraping Utility for lazy people.\nMIT Licensed\n\nHere's a simple node module that will allow you to asynchronously scrape opengraph tags, microformats, microdata, header tags, images, classic meta, and whatever else you want with minimal effort.\nYou can output the scraped data in the command line, or you can output scraped data as a JSON object.\nIf you don't want the scraped data yet, and still want to fine tune and grab more data from the html, no problem.  You can extend suq as much as you want, it doesn't care.\n\n\nRecipes\nCommand line Usage\nBasic Usage\nOpengraph\nMicroformat\nMicrodata\nHeaders\nImages\nMeta\nOptions\nSignature\nExtending\nMentions\n\n\nCommand line usage:\n\nScrape a website and output the data to command line.\n\nsuq can be used in the command line when installed globally, outputting scraped data to stdout\n\nnpm install suq -g\n\nsuq http://www.example.com > example.json\n\nsuq -u http://www.example.com -o example.json\n\nsuq --url http://www.example.com --output example.json\n\n\n\nBasic usage\n\nHow to scrape a website and convert structured data to json, and keep the html data as well (in case you're not done with it yet)\n\nvar suq = require('suq');\n\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        console.log('scraped json is:', JSON.stringify(json, null, 2));\n        console.log('html body is', body);\n    }\n\n});\n\n\nOpengraph\n\nHow to scrape a website and store its opengraph tags.\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var openGraphTags = json.og;\n        console.log(JSON.stringify(openGraphTags, null, 2));\n    }\n\n});\n\n\nMicroformat\n\nHow to scrape a website and store its microformats version 1 and 2 data.\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var microformat = json.microformat;\n        console.log(JSON.stringify(microformat, null, 2));\n    }\n\n});\n\n\nMicrodata\n\nHow to scrape a website and store its schema.org microdata.\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var microdata = json.microdata;\n        DoSomethingCool(microdata);\n    }\n\n});\n\n\nHeaders\n\nHow to scrape header tags from a URL:\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var headers = json.headers;\n\n        var title = json.headers.h1[0];\n        var subtitle = json.headers.h2[0];\n\n    }\n\n});\n\n\nImages\n\nHow to scrape image tag URLS from a website:\n\nvar suq = require('suq');\nvar _ = require('lodash');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var images = json.images;\n\n        _.each(images, function (src) {\n            makeSomeHTML('<img src=\"' + src + '\"/>');\n        });\n\n    }\n\n});\n\n\nMeta\n\nHow to scrape meta title and description from a URL:\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var title = json.meta.title;\n        var description = json.meta.description;\n    }\n\n});\n\nOptions\n\nYou can customize what SUq pulls from websites by using options (everything is turned on by default)\n\nHere is how you can scrape nothing but open graph tags:\n\nvar suq = require('suq');\nvar url = \"http://www.example.com\";\nvar options = {\n    meta: false,\n    microdata: false,\n    microformats: false,\n    headers: false,\n    images: false,\n    og: true // or leave this blank since it is true by default\n}\n\nsuq(url, function (err, json, body) {\n\n    if (!err) {\n        var openGraphTags = json.og;\n        console.log(JSON.stringify(openGraphTags, null, 2));\n    }\n\n}, options);\n\nOutput\n\nTBD\n\nOptions Table\n\n\n\nmetascrape meta tags\nmicrodatascrape microdata\nmicroformatsscrape microformats\nheadersscrape headers\nimagesscrape images\nogscrape open graph\n\n\n\n\nRemember, Everything is enabled by default.\n\n\nSignature\n\nIf you are familiar with signature patterns, you may find this helpful.  If not, you may ignore this :)\n\nsuq(String url, Callback( JSON err, JSON json, String body ) callback, Object options);\n\nExtending\n\nSUq is a node module that lets you scrape website data and customize what you want because it doesnt drop the html body from the request.\n\nIn this example we scrape an unordered list with the class \"grocerylist\" and scrape all the p tags too for fun.\n\nvar suq = require('suq');\nvar cheerio = require('cheerio');\nvar url = \"http://www.example.com\";\n\nsuq(url, function (err, json, body) {\n\n    var $ = cheerio.load(body);\n\n\n    $('body').find('p').each(function(i, el) {\n\n        json.pTags.push($(el).text().trim());\n\n    });\n\n    $('body').find('ul.grocerylist').find('li').each(function(i, el) {\n\n        json.groceryList.push($(el).text().trim());\n\n    });\n\n    NowDoSomethingCool(json);\n});\n\nMentions\n\nSUq was made possible by:\n\n\ncheerio by Matt Mueller\nlodash by John-David Dalton\nmicrodata-node by Jan Potoms\nmicroformat-node by Glenn Jones\nminimist by James Halliday\nrequest by Mikeal Rogers\nopenGraphScraper by Josh Shemas\nAnd of course the awesome folks over at nodeJS.org\n\n\nA huge THANK YOU goes out to all of you for making this easy for me..  :)\n\nTODOS:\n\n\nAdd more explanations regarding options\n\n",
      "keywords": "JavaScript"
    },
    "path": [
      "items",
      "0",
      "type"
    ],
    "length": 2
  },
  {
    "type": "http://data-vocabulary.org/Breadcrumb",
    "props": {
      "title": "MattMcFarland",
      "url": "/MattMcFarland"
    },
    "path": [
      "items",
      "1",
      "type"
    ],
    "length": 2
  }
]
